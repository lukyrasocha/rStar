Namespace(note='default', seed=42, api='vllm', model_ckpt='microsoft/Phi-3-mini-4k-instruct', root_dir='r/dtu/blackhole/17/209207/DL_project/rStar/run_outputs/GSM8K/Mistral-7B-v0.1/test_0_29', dataset_name='GSM8K', resume=None, threshold=0.999, max_num_seqs=256, multi_choice_prompt_type=None, mask_left_boundary=0.2, mask_right_boundary=0.5, num_masked_solution_traces=4, rc_mode='mid', rc_temperature=1.0, rc_n_completions=1, rc_criteria='reward', cutoff_rollout=-1, start_idx=-1, end_idx=-1, fewshot_config_path='prompts/GSM8K/fewshot_cot/fewshot_cot_config.json', fewshot_prompt_path='prompts/GSM8K/fewshot_cot/fewshot_cot_prompt.txt')
INFO 11-18 12:59:33 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='microsoft/Phi-3-mini-4k-instruct', speculative_config=None, tokenizer='microsoft/Phi-3-mini-4k-instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=microsoft/Phi-3-mini-4k-instruct, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23198385: <evaluate_mistral_discriminate> in cluster <dcc> Exited

Job <evaluate_mistral_discriminate> was submitted from host <hpclogin1> by user <s240466> in cluster <dcc> at Mon Nov 18 12:59:19 2024
Job was executed on host(s) <4*n-62-18-8>, in queue <c02516>, as user <s240466> in cluster <dcc> at Mon Nov 18 12:59:21 2024
</zhome/26/8/209207> was used as the home directory.
</dtu/blackhole/17/209207/DL_project/rStar> was used as the working directory.
Started at Mon Nov 18 12:59:21 2024
Terminated at Mon Nov 18 12:59:34 2024
Results reported at Mon Nov 18 12:59:34 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#BSUB -q c02516
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -J evaluate_mistral_discriminate
#BSUB -n 4
#BSUB -R "span[hosts=1]"
#BSUB -R "rusage[mem=40GB]"
#BSUB -W 12:00
#BSUB -o evaluate_mistral_discriminate%J.out
#BSUB -e evaluate_mistral_discriminate%J.err

# Activate conda environment
source /dtu/blackhole/17/209207/miniconda3/bin/activate
conda activate DL_project

#### Set environment variables ####
export TMPDIR=/dtu/blackhole/17/209207/tmp
export TEMP=/dtu/blackhole/17/209207/tmp
export TMP=/dtu/blackhole/17/209207/tmp

export HF_HOME=/dtu/blackhole/17/209207/huggingface_cache
export HUGGING_FACE_HUB_TOKEN=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  # Replace with your actual token

unset TRANSFORMERS_CACHE

# Run your script with --half_precision
python run_src/do_discriminate.py \
    --model_ckpt microsoft/Phi-3-mini-4k-instruct \
    --root_dir r/dtu/blackhole/17/209207/DL_project/rStar/run_outputs/GSM8K/Mistral-7B-v0.1/test_0_29 \
    --dataset_name GSM8K \
    --note default \

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   9.20 sec.
    Max Memory :                                 389 MB
    Average Memory :                             389.00 MB
    Total Requested Memory :                     163840.00 MB
    Delta Memory :                               163451.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   16 sec.
    Turnaround time :                            15 sec.

The output (if any) is above this job summary.



PS:

Read file <evaluate_mistral_discriminate23198385.err> for stderr output of this job.

